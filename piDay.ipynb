{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pi Day - Pi / Not Pi \n",
    "\n",
    "![](./images/pienpi.png)\n",
    "\n",
    "## What it is\n",
    "\n",
    "* A CNN (ResNet) based image classification built on SageMaker\n",
    "* Optimized & complied with SageMaker Neo \n",
    "* Running inference on the edge - Raspberry Pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre processing \n",
    "\n",
    "### Generate synthetic data \n",
    "\n",
    "Before we can train, we need to generate some additional data - synthetic data that can be used to train the classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Libraries**\n",
    "\n",
    "Load python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageEnhance\n",
    "from skimage.transform import resize\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import uuid\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Display Functions**\n",
    "\n",
    "Function to display / plot images as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotImages(pathList, number):\n",
    "    pp = list(pathList)\n",
    "    plt.figure(figsize=(15,15))\n",
    "    for i in range(number):\n",
    "        plt.subplot(5,5,i+1)\n",
    "        im = Image.open( pp[i] )\n",
    "        plt.imshow(im)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import data from S3 to local instance**\n",
    "\n",
    "Get raw data from S3 to your local instance for pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive s3://{inputbucketname} ./images/ > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define base directories**\n",
    "\n",
    "Define base directories in your local instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputBasePath = './images/'\n",
    "outputBasePath = './output/'\n",
    "resizeBasePath = './resize/'\n",
    "folders = ['pie', 'notpie']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resize images**\n",
    "\n",
    "Resize images to the same size so they can be fed to a fixed input layer. Also add randomness to the file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newsize = (244, 244)\n",
    "for f in folders:\n",
    "    plist = Path(inputBasePath + f + '/').glob('*.jpeg')\n",
    "\n",
    "    resizepath = resizeBasePath + f + '/' \n",
    "    if not os.path.exists(resizepath):\n",
    "        os.makedirs(resizepath)\n",
    "    for path in plist:\n",
    "        i = Image.open( path )\n",
    "        i = i.resize(newsize)\n",
    "        save(i, resizepath + str(uuid.uuid4()) + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check image sizes\n",
    "im = Image.open('./resize/notpie/0efdfa1d-3ce1-4306-b2c2-65644ac70173.png')\n",
    "Image(file_name)\n",
    "print(im.size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate sythetic data**\n",
    "\n",
    "Define transformations and generate synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rotations = [0,90,180,270]\n",
    "randContrastMin, randContrastMax = (0.8, 1.2)\n",
    "randSharpenMin, randSharpenMax  = (0.8, 1.2)\n",
    "randColorMin, randColorMax    = (0.8, 1.2)\n",
    "multiplier = 3\n",
    "\n",
    "for f in folders:\n",
    "    plist = Path(resizeBasePath + f + '/').glob('*.png')\n",
    "\n",
    "    outpath = outputBasePath + f + '/' \n",
    "    if not os.path.exists(outpath):\n",
    "        os.makedirs(outpath)\n",
    "    \n",
    "    for path in plist:\n",
    "        i = Image.open( path )\n",
    "\n",
    "        for r in rotations:\n",
    "            \n",
    "            for m in range(multiplier):\n",
    "                \n",
    "                randContrast = random.uniform(randContrastMin, randContrastMax)\n",
    "                randSharpen = random.uniform(randSharpenMin, randSharpenMax)\n",
    "                randColor = random.uniform(randColorMin, randColorMax)\n",
    "                \n",
    "                i = rotate(i, r)\n",
    "                i = contrast(i, randContrast)\n",
    "                i = sharpen(i, randSharpen)\n",
    "                i = color(i, randColor)\n",
    "                \n",
    "                save(i, outpath + str(uuid.uuid4()) + '.png') \n",
    "                print('.', end='')\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Prep**\n",
    "\n",
    "Shuffle the images and split for training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allImages = []\n",
    "for f in folders:\n",
    "    for p in Path(outputBasePath + f + '/').glob('*.png'):\n",
    "        allImages.append(str(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(allImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valLen = int(len(allImages)/4)\n",
    "trainLen = len(allImages) - valLen\n",
    "trainImg = allImages[:trainLen]\n",
    "valImg  = allImages[1-valLen-1:]\n",
    "print(trainLen, valLen)\n",
    "plotImages(allImages, 25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create LST files**\n",
    "\n",
    "Create LST files - labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./output/train_lst.lst\", \"w+\")\n",
    "x = 0\n",
    "for i in trainImg:\n",
    "    x = x + 1\n",
    "    if 'notpie' in i:\n",
    "        f.write(\"%i\\t0\\t%s\\n\" % (x, i[7:]))\n",
    "    else:\n",
    "        f.write(\"%i\\t1\\t%s\\n\" % (x, i[7:]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"./output/validation_lst.lst\", \"w+\")\n",
    "x = 0\n",
    "for i in valImg:\n",
    "    x = x + 1\n",
    "    if 'notpie' in i:\n",
    "        f.write(\"%i\\t0\\t%s\\n\" % (x, i[7:]))\n",
    "    else:\n",
    "        f.write(\"%i\\t1\\t%s\\n\" % (x, i[7:]))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Write data back to S3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp --recursive ./output/ s3://{outputbucketname}/ > /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Classification Model\n",
    "\n",
    "**Import Packages and Setup**\n",
    "\n",
    "Start by setting your default S3 bucket. Next we import the SageMaker package and get the execution role. Also create a SageMaker session.\n",
    "Since we are using the SageMaker builtin image classification algorithm, specify the training image as `image-classification` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket= 'sampal-pi5'\n",
    "#prefix = 'output'\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "print(role)\n",
    "sess = sagemaker.Session()\n",
    "\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "\n",
    "training_image = get_image_uri(sess.boto_region_name, 'image-classification', repo_version=\"latest\")\n",
    "print (training_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Specify the channels for training & validation data & LST files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3train = 's3://{}/'.format(bucket,prefix)\n",
    "s3validation = 's3://{}/'.format(bucket,prefix)\n",
    "s3train_lst = 's3://{}/train_lst.lst'.format(bucket,prefix)\n",
    "s3validation_lst = 's3://{}/validation_lst.lst'.format(bucket,prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (s3train)\n",
    "print (s3validation)\n",
    "print(s3train_lst)\n",
    "print(s3validation_lst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Model Build**\n",
    "\n",
    "Create the Estimator object to define the model and set hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_output_location = 's3://{}/output'.format(bucket, prefix)\n",
    "ic = sagemaker.estimator.Estimator(training_image,\n",
    "                                         role, \n",
    "                                         train_instance_count=1, \n",
    "                                         train_instance_type='ml.p2.xlarge',\n",
    "                                         train_volume_size = 50,\n",
    "                                         train_max_run = 360000,\n",
    "                                         input_mode= 'File',\n",
    "                                         output_path=s3_output_location,\n",
    "                                         sagemaker_session=sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic.set_hyperparameters(num_layers=152,\n",
    "                             use_pretrained_model=0,\n",
    "                             image_shape = \"3,224,224\",\n",
    "                             num_classes=2,\n",
    "                             mini_batch_size=32,\n",
    "                             epochs=30,\n",
    "                             learning_rate=0.01,\n",
    "                             num_training_samples=963,\n",
    "                             precision_dtype='float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Define Data Channels**\n",
    "\n",
    "Pass the channels to be used for training. Also specify distribution type here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.session.s3_input(s3train, distribution='FullyReplicated', \n",
    "                        content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "validation_data = sagemaker.session.s3_input(s3validation, distribution='FullyReplicated', \n",
    "                             content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "train_data_lst = sagemaker.session.s3_input(s3train_lst, distribution='FullyReplicated', \n",
    "                        content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "validation_data_lst = sagemaker.session.s3_input(s3validation_lst, distribution='FullyReplicated', \n",
    "                             content_type='application/x-image', s3_data_type='S3Prefix')\n",
    "\n",
    "data_channels = {'train': train_data, 'validation': validation_data, \n",
    "                 'train_lst': train_data_lst, 'validation_lst': validation_data_lst}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training**\n",
    "\n",
    "Start the training job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ic.fit(inputs=data_channels, logs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SageMaker Neo**\n",
    "\n",
    "Compile and optimize the model using Neo API. In this case specfically for the Raspberry Pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_ic = ic.compile_model(target_instance_family='rasp3b', \n",
    "                                input_shape={'data':[1, 3, 224, 224]},  # Batch size 1, 3 channels, 224x224 Images.\n",
    "                                output_path=s3_output_location,\n",
    "                                framework='mxnet', framework_version='1.2.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Deploy**\n",
    "\n",
    "Deploy the optimized model for testing using an endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_ic.image = get_image_uri(sess.boto_region_name, 'image-classification-neo', repo_version=\"latest\")\n",
    "optimized_ic.name = 'deployed-image-classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_ic_classifier = optimized_ic.deploy(initial_instance_count = 1,\n",
    "                                              instance_type = 'ml.c5.4xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test Inference**\n",
    "\n",
    "Test inference via the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = './pie.png'\n",
    "# test image\n",
    "from IPython.display import Image\n",
    "Image(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "with open(file_name, 'rb') as f:\n",
    "    payload = f.read()\n",
    "    payload = bytearray(payload)\n",
    "    \n",
    "optimized_ic_classifier.content_type = 'application/x-image'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = json.loads(optimized_ic_classifier.predict(payload))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleanup**\n",
    "\n",
    "Delete the endpoint to avoid recurring charges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_ic_classifier.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
